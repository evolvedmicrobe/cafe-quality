%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stylish Article
% LaTeX Template
% Version 2.0 (13/4/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left


%----------------------------------------------------------------------------------------
%	Source Code Listings
%----------------------------------------------------------------------------------------
\usepackage{listings}
\usepackage{xcolor}
\definecolor{darkgreen}{rgb}{0.0, 0.2, 0.13}
\definecolor{ao}{rgb}{0.0, 0.5, 0.0}
\lstdefinestyle{sharpc}{language=[Sharp]C, frame=single}
\lstset{% general command to set parameter(s)
basicstyle=\small, % print whole listing small
keywordstyle=\color{blue}\bfseries,
% underlined bold black keywords
commentstyle=\small\color{ao}, % white comments
stringstyle=\ttfamily, % typewriter type for strings
columns=fullflexible, % keeps the comments from exploding
showstringspaces=false} % no special string spaces


%----------------------------------------------------------------------------------------
%	COLUMNS
%----------------------------------------------------------------------------------------

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

%----------------------------------------------------------------------------------------
%	COLORS
%----------------------------------------------------------------------------------------

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------

\usepackage{hyperref} % Required for hyperlinks
\hypersetup{hidelinks,colorlinks,breaklinks=true,urlcolor=color2,citecolor=color1,linkcolor=color1,bookmarksopen=false,pdftitle={Title},pdfauthor={Author}}

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\JournalInfo{PBEP \#78, 2015} % Journal information
\Archive{Additional note} % Additional notes (e.g. copyright, DOI, review/research article)

\PaperTitle{PacBio Enhancement Proposal \#((int)`N') \\{\large Removing the deletion tag value from secondary analysis}} % Article title

\Authors{Nigel Delaney} % Authors

\Keywords{} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{ The PacBio consensus calling framework is complicated by the presence of deletion tag values attached to certain basepairs.  This PBEP reviews how these values are generated and evaluates from a principled and empirical perspective why they are undesirable.  It concludes that the CCS algorithm could likely benefit from richer deletion QV values, but that the DelTag value is expected to only complicate matters at present. }

%----------------------------------------------------------------------------------------

\begin{document}

\flushbottom % Makes all text pages the same height

\maketitle % Print the title and abstract box

\tableofcontents % Print the contents section

\thispagestyle{empty} % Removes page numbering from the first page

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{Introduction} % The \section*{} command stops section numbering

\addcontentsline{toc}{section}{Introduction} % Adds this section to the table of contents

A desirable statistical model is no more complex than necessary, does not contain unnecessary parameters and has a likelihood function that is smooth and continuous to aid in optimization.  There should also be a well defined generative process that defines how the observed data should be interpreted.

The use of Deletion Tags (DelTags), in secondary analysis takes the CCS and Quiver models further away from, rather than closer to, this ideal.  The proposal suggests that either DelTag values should be ignored during CCS analysis or promoted to an actual base in the read sequence, so that it could be handled using the framework for insertions/deletions already present in the scoring models that does not require DelTag values. 

Here, I review the origin and rational for deletions tags then present several arguments for their removal. 



\subsection{What are DelTags?}
Each base in a PacBio dataset may have an associated DelTag value which is one of the basepairs A, C, G, T.  It is defined in the PacBio documentation as the \textit{``Likely identity of a deleted base, if it exists"}.  In practice, typically approximately 10\% of bases in a dataset will have this value, while the remainder will have an `N' value to indicate the DelTag was never set.  The exact percentage of bases with a DelTag varies by overall read quality as shown in Figure \ref{fig:RateByRQ}\footnote{Generated using code in ExamineDelTags.fs and ExamineDelTags.R.}.  The DeletionTag value is created within the method that converts pulses into bases\footnote{Method: \texttt{ AnalyzeInsertClassify@PulseToBaseStream.cs:521}}.

\begin{figure}[ht]\centering 
\includegraphics[width=\linewidth]{TagRateByRQ}
\caption{DelTag Appearance Rate by Read Quality.  Each dot represents the average percentage of non `N' DelTags that appeared in reads with the RQ value given by the position along the x-axis. }
\label{fig:RateByRQ}
\end{figure}


Before discussing when and how DelTags are added, it is worth mentioning that generally speaking, the Deletion QV values emitted from PacBio data processing are not very useful, and their calculation appears to be an unfinished project.  It appears Pat originally intended to create Deletion QV values using a GBM\footnote{Generalized Boosted Model, for more details see the R package GBM.} to predict the likelihood of error, as is currently done for insertion QVs.  However, at present the values for the deletion QV are all hardcoded to a QV of 17 (corresponding to a 2\% error rate) with the following line of code:\footnote{\texttt{PulseToBaseStream.cs:478}}

\lstset{style=sharpc}
\begin{lstlisting}[frame=single]
/* This could be done much more intelligently.
  We weren't really able to get a DeletionClassifier
  to give much benefit. */
delPrediction = incPredictions.Map(v => 0.02f);
\end{lstlisting}

Although all DeletionQV values are initially hard-coded to the seemingly arbitrary 17 value in PulseToBases, this value can later be modified if and only if when converting pulses to bases some pulses are not emitted, or are skipped.  If a pulse is skipped, then a new DeletionQV value, and a DelTag, is attached to the next pulse converted to a base.  This is the only time a DelTag will exist.

To calculate both the DelTag base and the QV value that will be attached to this base, all pulses skipped before the emitted pulse are evaluated.  The basepair of the skipped pulse with the highest probability of incorporation becomes the DelTag basepair.  A new DeletionQV value is then calculated as the sum of all the deletion probabilities for the skipped pulses (which are all a fixed constant), plus the probability of incorporation for the most likely base.  The specific code to do this is shown below.\footnote{\texttt{PulseToBaseStream.cs:636}}

\lstset{style=sharpc}
\begin{lstlisting}[frame=single]
// sum up all the deletion probability since the last base
float dqvs1 = 0.0;
// We did skip some pulses since the last base
// For now lets just consider the one that was closest to being a base
float skippedIncMax = float.MinValue;
int worstSkippedPulseIndex = 0;
// This could use a bit of attention
foreach(var p in skippedPulses) {
    if(incPredictions[p] > skippedIncMax)    {
        skippedIncMax = incPredictions[p];
        worstSkippedPulseIndex = p;
    }
    dqvs1 += delPredictions[p];
}
/*  Total probability of a deletion is the sum of the bg deletion rates 
over the gaps, plus the incorporation probability of the leftover 
pulse. */
delProb = dqvs1 + incPredictions[worstSkippedPulseIndex];
delQV.Add(QVs.ProbToQV(delProb));
delTag.Add(iBases[worstSkippedPulseIndex]);
\end{lstlisting}

The algorithm in this code is wrong for several reasons.  First, when considering deletion events before each pulse, this code sums the deletion probabilities before each pulse that is skipped. The correct calculation, given the fixed value of 0.02 for $N$ skipped pulses would be to account for the probability that there were no deletions before each pulse as: $ (1 - (1-.02)^N)$.  Fortunately (or perhaps by uncommented design), because the fixed constant currently used as the default deletion probability is small, the summation used and the correct formula should often give similar results as $(1-0.02)^N \thickapprox 1 - N\cdot0.02$.  However, this will not generally be true for larger fixed constants and/or a large number of skipped pulses.

The second issue is that only the pulse with the highest probability of being a true incorporation is considered.  The correct formula for multiple skipped pulses would be similar to the one given in the last paragraph, but replacing the fixed constant with the value for each pulse's incorporation probability.  As before, the calculation currently used may approximate the correct value under some conditions, in particular if there is only one skipped pulse or if only one pulse has any meaningful incorporation probability.  Also as before, these conditions may not always hold. 


 



%------------------------------------------------

\section{Principled Arguments Against DelTags}



\subsection{They make scoring complex}

The ``Deletion Move" in our template scoring routine is done in one of two distinct ways depending on if a DelTag is present.  With positions denoted by Figure \ref{fig:del}, a deletion move is currently scored according to the equation shown below.  

\begin{figure}[ht]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
\includegraphics[width=\linewidth]{Deletion}
\caption{Deletion Scoring}
\label{fig:del}
\end{figure}

\[
	\alpha_{i,j-1}  +  \begin{cases}
							 \text{Deletion score  for } R_{i+1}  & \text{if }  \text{DeletionTag}_{i+1} = T_{j} \\
							 \text{A fixed constant} & \text{if }  \text{DeletionTag}_{i+1} \neq T_{j} 
							 \end{cases}
\]

By having two possible scoring methods, we not only need to estimate 3 parameters for the deletion move in training, but we also are scoring the same behavior (a deletion in the template), using two separate methods.  This additional step further exacerbates the complexity when deletions in homopolymer regions (the main error mode for CCS P6-C4 PacBio data) are considered.  For example, consider the alignment:

\begin{center}
\texttt{GGGG}

\texttt{GG-G}
\end{center}

The deletion in this alignment can be explained by either a single merge move or a deletion move followed by a match.  Because deletions can be scored in one of two ways depending on the deletion tag values, this creates three separate possible scorings for the single deletion and makes the score affected by at least 5 parameters that need to be trained in order to compare these possibilities (1 for the baseline deletion penalty, 2 for the affine transform used if a DelTag exists and 2 more to transform the MergeQV).  Such complexity makes it difficult to analyze and optimize the scoring model.

\subsection{Knowing the identity of the base most likely to have been deleted should not add value.}

The algorithm should be able to ignore the specific base specified by the DelTag and work just as well.  Here's why: If the sequence \texttt{GGGG} was accidentally emitted as \texttt{GGG} due to a pulse with a `G' being skipped and emitted as a DelTag, we would not expect the other reads from this template to generate odd sequences with a random base inserted,  such as \texttt{GGAG} or \texttt{GGCG}.  Because single read PacBio data is correct $\sim87\%$ of the time, instead we would expect most of the other reads we consider to represent the true sequence, i.e. \texttt{GGGG}.  In general, when generating a consensus with multiple reads we will always be debating between the true sequence and a sequence close to truth, i.e. \texttt{GGGG} versus \texttt{GGG}.

As a consequence of this, with multiple reads being used to generate a consensus, the algorithm can and will determine what the most likely alternate base was using the other reads, not the DelTag.  If \texttt{GGGG} shows up in several reads, we should expect and hope that the reads with \texttt{GGG} contain a DeletionTag with a value of `G'.  It would be an improbable world if by ignoring the DelTag value, the algorithm accepted the sequence \texttt{GGGG} over \texttt{GGG} only because it weighed several DelTag values and assumed they were `G' even though they were `A', `C', or `T'. 

In other words, \textit{we don't need to encode the most likely deleted base in the DelTag because it is already encoded by the other reads used for consensus}. 
 





%------------------------------------------------

\section{Empirical Arguments Against DelTags}

\subsection{They are rarely correct.}

The overall rate at which a DelTag is correct is only $\sim3.6\%$ and this value does not improve much based on read quality as can be seen in Figure \ref{fig:rateCorrect}.  


\begin{figure}[ht]\centering
\includegraphics[width=\linewidth]{TagCorrectRateByRQ.pdf}
\caption{Percentage of DelTags Correct by RQ.  For each DelTag in an aligned set of subreads, DelTags were counted as correct if when aligned to a reference they came after a deletion of the given base in the alignment (with some accounting for different alignments within homopolymers, though this may be an underestimate of the true rate is it in contingent on a particular alignment).  Each dot in this graph represents the average for a set of subreads binned by RQ. For more details, see the cafe-quality commit \texttt{c0a4384}}.
\label{fig:rateCorrect}
\end{figure}

\subsection{Ignoring them can improve accuracy}

The presence of a DelTag value simultaneously does two things: it provides a condition under which a different Deletion QV value will be used, and it provides a QV value to use if that condition is met.  It can be that of these two things \textit{the alternate QV value is important, but the condition under which to use it is not}.

A simple experiment helps to demonstrate this.  Figure \ref{fig:lambdaTest} shows how the empirically observed error rate (Phred Scaled) for data derived from the $\lambda$ genome using the current version 2.3 P6-C4 CCS analysis as well as two variants of it\footnote{Code to run comparison is in Cafe-Quality, branches \texttt{del\_tag\_all\_match:522aae7} and \texttt{no\_del\_tag:f6b0952}.  Figures from R script \texttt{CompareDelTagPolishOnLambda.R}}.  In the first alogrithmic variant (referred to as \textbf{Never use}) we remove all DelTag values from the dataset before analysis so that only the constant term is used to score deletions.  As the figure evinces, this lowers the accuracy at all coverage levels in the data, indicating using the alternate QV value is important.

In the second variation of the algorithm shown (referred to as \textbf{Always Use}) the QV value associated with the DelTag is always used, with no requirement that the base in the template being considered matches the base specified by the DelTag.  The figure shows that although initially not considering the DelTag increases the error rate.  At around 15X coverage (corresponding to a Phred Scaled error rate of $\sim27$ for the original algorithm), the error rate obtained by always using the DelTag QV score is lower than that obtained by using it, and it continues to drop until it has about $\sim30\%$ fewer errors at high coverage levels. 

This demonstrates that under some conditions ignoring the DelTag value is beneficial.  Not ignoring it appears most beneficial for the areas used for training, namely at coverage levels between 3X and 9X.  Current work is exploring how this ``Always Use" algorithmic variant would performs if the CCS parameters are retrained with it.

\begin{figure*}[ht]\centering
\includegraphics[width=\linewidth]{LambdaComparison.pdf}
\caption{Evaluating how accuracy changes for two variations of the CCS scoring algorithm.   }
\label{fig:lambdaTest}
\end{figure*}




%------------------------------------------------


\section{Conclusions and Possibilities}
PacBio Deletion QV values are effectively hard coded to a constant for $\sim90\%$ of emitted bases.  This is despite the fact that deletion rates empirically are observed to vary across different SNR and template contexts.

An exception to this hard-coded rule exists for $\sim10\%$ of emitted bases which have a DelTag emitted along with them, and in this case a different QV value can be used if a certain condition is met between the template and the read being considered.  The presence of this alternative QV value is clearly useful -- the accuracy drops if it is never considered and  frequent trainings designed to find optimum transformations of the QV values prior to scoring have made the penalty for a deletion with an appropriate DelTag less than the penalty for a standard deletion.

However, although one can certainly see the intuition behind generating the DelTag value and reasons it may be useful, a simpler model could generate a single deletion QV value for all bases, and would use this value regardless of whether the DeletionTag matched.  We should expect that if we have enough data to make high accuracy calls, the information present in the DelTag could be provided by the other reads being used to generate the consensus, and that the information obtained from one pulse not deemed worthy enough to be turned into a base should not aid the algorithm much, and may hinder it if this information represents the wrong or incorrect base.  The DelTag gives value in that it indicates this base came from a noisy region, but in attempting to pick out the most likely base from that noise it likely adds more complexity than justified.

As such, this enchancement proposal is to:
\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a compact look
\item Ignore the particular DelTag value in CCS analysis 
\item Revisit the underling model for determining Deletion QVs, and attempt to obtain an informative value that will appear for all bases.  
\end{itemize}
 
This proposal does not suggest we stop emitting the DelTags, as they could still be useful for diagnostic purposes.  Similarly, when revising how deletion QVs are calculated, this covariate might be incorporated at that stage.  However, to aid analyzing, diagnosing and optimizing the CCS scoring model, it argues that it should be ignored. Model building always involves trade-offs, but DelTags introduce more complexity than they currently justify.



%----------------------------------------------------------------------------------------

\end{document}